{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# INFO-371 Final Project\n",
    "\n",
    "This is our final project which attempts to predict which events in a participant's accelerometer data signals\n",
    "the beginning and end of sleep. Over the course of many nights, accelerometer data is collected from a worn\n",
    "device on the participant's wrist at every moment of the day. Sleep scientists then annotate this data with\n",
    "events labeled \"onset\", signaling the participant has begun sleeping, or \"wakeup\", signaling the participant\n",
    "has just awoken.\n",
    "\n",
    "By analysing this time series data, in this notebook we create a prediction model using data mining and machine\n",
    "learning."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import pathlib\n",
    "import arff\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "\n",
    "# Set up data directories\n",
    "input_data_dir = os.path.join(os.path.realpath(pathlib.Path().cwd()), 'input_data')\n",
    "output_data_dir = os.path.join(os.path.realpath(pathlib.Path().cwd()), 'output_data')\n",
    "\n",
    "# Set up input files\n",
    "train_events_file = os.path.join(input_data_dir, 'train_events.csv')\n",
    "train_series_file = os.path.join(input_data_dir, 'train_series.parquet')\n",
    "# Set up output files\n",
    "rows_delete_file = os.path.join(output_data_dir, \"rows_to_delete.csv\")\n",
    "sleep_delta_file = os.path.join(output_data_dir, 'sleep_delta_data.parquet')\n",
    "sleep_delta_file_arff = os.path.join(output_data_dir, 'sleep_delta_data.arff')\n",
    "condensed_sdf_arff = os.path.join(output_data_dir, 'sleep_delta_data_condensed.arff')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Transform the train_events dataset types\n",
    "train_events = pd.read_csv(train_events_file, usecols=['series_id', 'event', 'step', 'night'])\n",
    "train_events.dropna(inplace=True)\n",
    "train_events.reset_index(inplace=True, drop=True)\n",
    "train_events['step'] = train_events['step'].astype(int)\n",
    "\n",
    "rows_to_delete = []\n",
    "\n",
    "train_events_n = len(train_events)\n",
    "\n",
    "# Locate pairs of onset and wakeup events, between which is relevant series data\n",
    "for index, row in train_events.iterrows():\n",
    "    delete = True\n",
    "    if index > 0:\n",
    "        previous_row = train_events.iloc[index - 1]\n",
    "        if previous_row['night'] == row['night'] and previous_row['event'] != row['event']:\n",
    "            delete = False\n",
    "\n",
    "    if index < train_events_n - 1:\n",
    "        next_row = train_events.iloc[index + 1]\n",
    "        if next_row['night'] == row['night'] and next_row['event'] != row['event']:\n",
    "            delete = False\n",
    "    if delete:\n",
    "        rows_to_delete.append(index)\n",
    "\n",
    "# Drop rows by their indices\n",
    "train_events.drop(rows_to_delete, inplace=True)\n",
    "train_events['series_id'] = train_events['series_id'].astype('category')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              series_id    step     anglez    enmo\n",
      "0          038441c925bb       0   2.636700  0.0217\n",
      "1          038441c925bb       1   2.636800  0.0215\n",
      "2          038441c925bb       2   2.637000  0.0216\n",
      "3          038441c925bb       3   2.636800  0.0213\n",
      "4          038441c925bb       4   2.636800  0.0215\n",
      "...                 ...     ...        ...     ...\n",
      "127946335  fe90110788d2  592375 -27.277500  0.0204\n",
      "127946336  fe90110788d2  592376 -27.032499  0.0233\n",
      "127946337  fe90110788d2  592377 -26.841200  0.0202\n",
      "127946338  fe90110788d2  592378 -26.723900  0.0199\n",
      "127946339  fe90110788d2  592379 -31.521601  0.0205\n",
      "\n",
      "[127946340 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load the series data\n",
    "train_series = pd.read_parquet(\n",
    "    train_series_file,\n",
    "    columns=[\"series_id\", \"step\", \"anglez\", \"enmo\"],\n",
    ")\n",
    "train_series['series_id'] = train_series['series_id'].astype('category')\n",
    "print(train_series)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Merge the two data frames\n",
    "merged_data = pd.merge_ordered(train_series, train_events, on=['series_id', 'step'])\n",
    "merged_data['series_id'] = merged_data['series_id'].astype('category')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Generate enmo + anglez deltas 1 row behind (5s ago) and 6 rows behind (30s ago)\n",
    "merged_data[['d1_enmo', 'd1_anglez']] = merged_data[['enmo', 'anglez']] - merged_data[['enmo', 'anglez']].shift(1)\n",
    "merged_data[['d6_enmo', 'd6_anglez']] = merged_data[['enmo', 'anglez']] - merged_data[['enmo', 'anglez']].shift(6)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "EVENT_WOKE = 'woke'\n",
    "EVENT_SLEEP = 'sleep'\n",
    "\n",
    "# Finding the rows that need to be deleted\n",
    "last_id = merged_data.iloc[0]['series_id']\n",
    "last_night = last_wakeup_index = 0\n",
    "rows_to_delete = []\n",
    "for index, row in merged_data.iterrows():\n",
    "    if row['event'] == 'onset':\n",
    "        merged_data.at[index + 1, 'event'] = EVENT_SLEEP\n",
    "        if row['night'] - last_night != 1 or row['series_id'] != last_id:\n",
    "            rows_to_delete.append((last_wakeup_index, index))\n",
    "            if row['series_id'] != last_id:\n",
    "                last_id = row['series_id']\n",
    "                last_night = row['night']\n",
    "        else:\n",
    "            last_night = row['night']\n",
    "    if row['event'] == 'wakeup':\n",
    "        merged_data.at[index + 1, 'event'] = EVENT_WOKE\n",
    "        last_wakeup_index = index\n",
    "\n",
    "# Write row deletions to csv outfile (recovery checkpoint)\n",
    "pd.DataFrame(data=rows_to_delete, columns=['wakeup', 'onset']).to_csv(rows_delete_file, index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Uncomment to load the deletion rows from csv (recovery checkpoint)\n",
    "# rows_to_delete = pd.read_csv(rows_delete_file).to_numpy()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Deleting the rows\n",
    "# 3 hour buffer\n",
    "buffer = 12 * 180\n",
    "\n",
    "# First six rows can be ignored because they will have NaN d6_ column data\n",
    "all_row_deletions = np.array(range(0, 6), dtype=np.uint32)\n",
    "for wakeup, onset in rows_to_delete:\n",
    "    all_row_deletions = np.hstack(\n",
    "        (all_row_deletions, np.arange(wakeup + buffer, onset - buffer - 1, dtype=np.uint32)),\n",
    "        dtype=np.uint32\n",
    "    )\n",
    "\n",
    "merged_data.drop(all_row_deletions, inplace=True)\n",
    "\n",
    "# Delete the 'night' col, we're finished with it\n",
    "merged_data.drop(columns='night', inplace=True)\n",
    "# Delete the 'step' and 'night' cols, we're finished with them\n",
    "# merged_data.drop(columns=['step', 'night'], inplace=True)\n",
    "merged_data.reset_index(inplace=True, drop=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# # Forward fill the events col\n",
    "merged_data.at[0, 'event'] = EVENT_WOKE\n",
    "merged_data.ffill(inplace=True)\n",
    "merged_data['event'] = merged_data['event'].astype('category')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# Drop the step column, we're finished with it\n",
    "merged_data.drop(columns='step', inplace=True)\n",
    "merged_data.reset_index(inplace=True, drop=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# Write transformed data to outfile\n",
    "merged_data.to_parquet(sleep_delta_file, index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             series_id     anglez    enmo event  d1_enmo  d1_anglez  d6_enmo  \\\n",
      "0         038441c925bb   2.636700  0.0217  woke   0.0000   0.000000   0.0000   \n",
      "1         038441c925bb   2.636700  0.0218  woke   0.0001   0.000000   0.0003   \n",
      "2         038441c925bb   2.798000  0.0223  woke   0.0005   0.161300   0.0007   \n",
      "3         038441c925bb   3.084700  0.0217  woke  -0.0006   0.286700   0.0004   \n",
      "4         038441c925bb   2.780200  0.0229  woke   0.0012  -0.304500   0.0014   \n",
      "...                ...        ...     ...   ...      ...        ...      ...   \n",
      "67027587  fe90110788d2 -27.277500  0.0204  woke   0.0001   0.172501   0.0007   \n",
      "67027588  fe90110788d2 -27.032499  0.0233  woke   0.0029   0.245001   0.0028   \n",
      "67027589  fe90110788d2 -26.841200  0.0202  woke  -0.0031   0.191299  -0.0002   \n",
      "67027590  fe90110788d2 -26.723900  0.0199  woke  -0.0003   0.117300  -0.0008   \n",
      "67027591  fe90110788d2 -31.521601  0.0205  woke   0.0006  -4.797701   0.0003   \n",
      "\n",
      "          d6_anglez  \n",
      "0          0.000000  \n",
      "1         -0.000100  \n",
      "2          0.161000  \n",
      "3          0.447900  \n",
      "4          0.143400  \n",
      "...             ...  \n",
      "67027587   0.622601  \n",
      "67027588   0.887201  \n",
      "67027589   1.081501  \n",
      "67027590   0.923401  \n",
      "67027591  -3.872501  \n",
      "\n",
      "[67027592 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "# Uncomment to load transformed data from outfile (recovery checkpoint)\n",
    "sleep_delta_data = pd.read_parquet(sleep_delta_file)\n",
    "sleep_delta_data.dtypes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Write arff file\n",
    "chunk_size = 100000\n",
    "total_rows = len(sleep_delta_data)\n",
    "num_chunks = math.ceil(total_rows / chunk_size)\n",
    "\n",
    "arff.dump(sleep_delta_file_arff\n",
    "      , sleep_delta_data.values\n",
    "      , relation='Movement_and_Sleep'\n",
    "      , names=sleep_delta_data.columns)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             anglez      enmo   d1_enmo  d1_anglez   d6_enmo  d6_anglez  \\\n",
      "index                                                                     \n",
      "0          2.742800  0.022000 -0.000017  -0.019367  0.000450   0.106000   \n",
      "1          2.412950  0.021533  0.000017  -0.017883 -0.000467  -0.329850   \n",
      "2         53.731201  0.019017 -0.002450   5.884783 -0.002517  51.318253   \n",
      "3        -13.351600  0.021250  0.001100 -19.618366  0.002233 -67.082802   \n",
      "4        -79.979088  0.013517  0.000117  -0.000417 -0.007733 -66.627487   \n",
      "...             ...       ...       ...        ...       ...        ...   \n",
      "11171261 -31.670416  0.012417  0.003217   0.494233  0.012417   1.904184   \n",
      "11171262 -30.088882  0.027950  0.002767  -0.234050  0.015533   1.581533   \n",
      "11171263 -28.166201  0.023433 -0.002583   0.681800 -0.004517   1.922683   \n",
      "11171264 -27.316267  0.020850 -0.000033   0.180250 -0.002583   0.849934   \n",
      "11171265 -29.122749  0.020200  0.000150  -2.340200 -0.000250  -1.474550   \n",
      "\n",
      "             series_id event  \n",
      "index                         \n",
      "0         038441c925bb  woke  \n",
      "1         038441c925bb  woke  \n",
      "2         038441c925bb  woke  \n",
      "3         038441c925bb  woke  \n",
      "4         038441c925bb  woke  \n",
      "...                ...   ...  \n",
      "11171261  fe90110788d2  woke  \n",
      "11171262  fe90110788d2  woke  \n",
      "11171263  fe90110788d2  woke  \n",
      "11171264  fe90110788d2  woke  \n",
      "11171265  fe90110788d2  woke  \n",
      "\n",
      "[11171266 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "# Remove wakeup and onset events\n",
    "sleep_delta_data = sleep_delta_data[(sleep_delta_data['event'] != 'onset') & (sleep_delta_data['event'] != 'wakeup')]\n",
    "\n",
    "# Group the entries\n",
    "factor = 6\n",
    "sleep_delta_data['group'] = sleep_delta_data.index // factor"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Aggregate the entries into groups, calculating the mean for numeric values and the mode for categorical ones\n",
    "aggregation_methods = {\n",
    "    'anglez': 'mean',\n",
    "    'enmo': 'mean',\n",
    "    'd1_enmo': 'mean',\n",
    "    'd1_anglez': 'mean',\n",
    "    'd6_enmo': 'mean',\n",
    "    'd6_anglez': 'mean',\n",
    "    'series_id': lambda x: x.mode()[0] if not x.mode().empty else None,\n",
    "    'event': lambda x: x.mode()[0] if not x.mode().empty else None,\n",
    "}\n",
    "condensed_df = sleep_delta_data.groupby('group').agg(aggregation_methods)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "# Write arff file\n",
    "factor = 10\n",
    "chunk_size = 100000\n",
    "total_rows = len(sleep_delta_data) // factor\n",
    "# num_chunks = math.ceil(total_rows / chunk_size)\n",
    "\n",
    "arff.dump(condensed_sdf_arff\n",
    "      , sleep_delta_data.head(total_rows).values\n",
    "      , relation='Movement_and_Sleep'\n",
    "      , names=sleep_delta_data.iloc[:total_rows].columns)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'condensed_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Load file, split it and save a part of it\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m \u001B[43mcondensed_df\u001B[49m\u001B[38;5;241m.\u001B[39mdrop([\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgroup\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mseries_id\u001B[39m\u001B[38;5;124m'\u001B[39m])\n",
      "\u001B[1;31mNameError\u001B[0m: name 'condensed_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Load file, split it and save a part of it\n",
    "condensed_df.drop(['group', 'series_id'])"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
