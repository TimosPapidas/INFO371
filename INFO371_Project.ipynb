{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# INFO-371 Final Project\n",
    "\n",
    "This is our final project which attempts to predict which events in a participant's accelerometer data signals\n",
    "the beginning and end of sleep. Over the course of many nights, accelerometer data is collected from a worn\n",
    "device on the participant's wrist at every moment of the day. Sleep scientists then annotate this data with\n",
    "events labeled \"onset\", signaling the participant has begun sleeping, or \"wakeup\", signaling the participant\n",
    "has just awoken.\n",
    "\n",
    "By analysing this time series data, in this notebook we create a prediction model using data mining and machine\n",
    "learning."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "\n",
    "# Set up data directories\n",
    "input_data_dir = os.path.join(os.path.realpath(pathlib.Path().cwd()), 'input_data')\n",
    "output_data_dir = os.path.join(os.path.realpath(pathlib.Path().cwd()), 'output_data')\n",
    "\n",
    "# Set up input files\n",
    "train_events_file = os.path.join(input_data_dir, 'train_events.csv')\n",
    "train_series_file = os.path.join(input_data_dir, 'train_series.parquet')\n",
    "# Set up output files\n",
    "rows_delete_file = os.path.join(output_data_dir, \"rows_to_delete.csv\")\n",
    "sleep_delta_file = os.path.join(output_data_dir, 'sleep_delta_data.parquet')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Transform the train_events dataset types\n",
    "train_events = pd.read_csv(train_events_file, usecols=['series_id', 'event', 'step', 'night'])\n",
    "train_events.dropna(inplace=True)\n",
    "train_events.reset_index(inplace=True, drop=True)\n",
    "train_events['step'] = train_events['step'].astype(int)\n",
    "\n",
    "rows_to_delete = []\n",
    "\n",
    "train_events_n = len(train_events)\n",
    "\n",
    "# Locate pairs of onset and wakeup events, between which is relevant series data\n",
    "for index, row in train_events.iterrows():\n",
    "    delete = True\n",
    "    if index > 0:\n",
    "        previous_row = train_events.iloc[index - 1]\n",
    "        if previous_row['night'] == row['night'] and previous_row['event'] != row['event']:\n",
    "            delete = False\n",
    "\n",
    "    if index < train_events_n - 1:\n",
    "        next_row = train_events.iloc[index + 1]\n",
    "        if next_row['night'] == row['night'] and next_row['event'] != row['event']:\n",
    "            delete = False\n",
    "    if delete:\n",
    "        rows_to_delete.append(index)\n",
    "\n",
    "# Drop rows by their indices\n",
    "train_events.drop(rows_to_delete, inplace=True)\n",
    "train_events['series_id'] = train_events['series_id'].astype('category')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Load the series data\n",
    "train_series = pd.read_parquet(\n",
    "    train_series_file,\n",
    "    columns=[\"series_id\", \"step\", \"anglez\", \"enmo\"],\n",
    ")\n",
    "train_series['series_id'] = train_series['series_id'].astype('category')\n",
    "\n",
    "# Merge the two data frames\n",
    "merged_data = pd.merge_ordered(train_series, train_events, on=['series_id', 'step'])\n",
    "merged_data['series_id'] = merged_data['series_id'].astype('category')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Generate enmo + anglez deltas 1 row behind (5s ago) and 6 rows behind (30s ago)\n",
    "merged_data[['d1_enmo', 'd1_anglez']] = merged_data[['enmo', 'anglez']] - merged_data[['enmo', 'anglez']].shift(1)\n",
    "merged_data[['d6_enmo', 'd6_anglez']] = merged_data[['enmo', 'anglez']] - merged_data[['enmo', 'anglez']].shift(6)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "EVENT_WOKE = 'woke'\n",
    "EVENT_SLEEP = 'sleep'\n",
    "\n",
    "# Finding the rows that need to be deleted\n",
    "last_id = merged_data.iloc[0]['series_id']\n",
    "last_night = last_wakeup_index = 0\n",
    "rows_to_delete = []\n",
    "for index, row in merged_data.iterrows():\n",
    "    if row['event'] == 'onset':\n",
    "        merged_data.at[index+1, 'event'] = EVENT_SLEEP\n",
    "        if row['night'] - last_night != 1 or row['series_id'] != last_id:\n",
    "            rows_to_delete.append((last_wakeup_index, index))\n",
    "            if row['series_id'] != last_id:\n",
    "                last_id = row['series_id']\n",
    "                last_night = row['night']\n",
    "        else:\n",
    "            last_night = row['night']\n",
    "    if row['event'] == 'wakeup':\n",
    "        merged_data.at[index+1, 'event'] = EVENT_WOKE\n",
    "        last_wakeup_index = index\n",
    "\n",
    "# Write row deletions to csv outfile (recovery checkpoint)\n",
    "pd.DataFrame(data=rows_to_delete, columns=['wakeup', 'onset']).to_csv(rows_delete_file, index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Uncomment to load the deletion rows from csv (recovery checkpoint)\n",
    "# rows_to_delete = pd.read_csv(rows_delete_file).to_numpy()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Deleting the rows\n",
    "# 3 hour buffer\n",
    "buffer = 12 * 180\n",
    "\n",
    "# First six rows can be ignored because they will have NaN d6_ column data\n",
    "all_row_deletions = np.array(range(0, 6), dtype=np.uint32)\n",
    "for wakeup, onset in rows_to_delete:\n",
    "    all_row_deletions = np.hstack(\n",
    "        (all_row_deletions, np.arange(wakeup + buffer, onset - buffer - 1, dtype=np.uint32)),\n",
    "        dtype=np.uint32\n",
    "    )\n",
    "\n",
    "merged_data.drop(all_row_deletions, inplace=True)\n",
    "\n",
    "# Delete the 'night' col, we're finished with it\n",
    "merged_data.drop(columns='night', inplace=True)\n",
    "# Delete the 'step' and 'night' cols, we're finished with them\n",
    "# merged_data.drop(columns=['step', 'night'], inplace=True)\n",
    "merged_data.reset_index(inplace=True, drop=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# # Forward fill the events col\n",
    "merged_data.at[0, 'event'] = EVENT_WOKE\n",
    "merged_data.ffill(inplace=True)\n",
    "merged_data['event'] = merged_data['event'].astype('category')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# Drop the step column, we're finished with it\n",
    "merged_data.drop(columns='step', inplace=True)\n",
    "merged_data.reset_index(inplace=True, drop=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# Write transformed data to outfile\n",
    "merged_data.to_parquet(sleep_delta_file, index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# Uncomment to load transformed data from outfile (recovery checkpoint)\n",
    "# sleep_delta_data = pd.read_parquet(sleep_delta_file)\n",
    "# sleep_delta_data.dtypes"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
